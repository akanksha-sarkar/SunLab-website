---
title: Pre-trained LLMs Can Learn HMMs In-context
status: inactive

description: |
  We show that pre-trained large language models can learn hidden Markov models through in-context learning, achieving near-optimal predictive performance distributions. On real-world animal decision-making tasks, this approach matches expert-designed models. This work advances our understanding of in-context learning and its potential for uncovering hidden structure in scientific data.

people:
  - Yijia
  - profx

layout: project
last-updated: 2015-05-05
---

We show that pre-trained large language models can learn hidden Markov models through in-context learning, achieving near-optimal predictive performance distributions. On real-world animal decision-making tasks, this approach matches expert-designed models. This work advances our understanding of in-context learning and its potential for uncovering hidden structure in scientific data.
