---
title: Benchmarking AI Agents for Neuroscience

description: |
  This project, in collaboration with HHMI Janelia, introduces a modular evaluation framework based on an end-to-end behavioral neuroscience pipeline to assess LLM coding agents and quantify how early-stage errors propagate to compromise downstream scientific analysis.

people:
  - profx
  - Kai

layout: project
last-updated: 2015-05-05
---

